REDIS_HOST = "localhost"
REDIS_PORT = 6379
REDIS_DB = 0

EMBED_MODEL = "all-MiniLM-L6-v2"
CHUNK_SIZE = 500
CHUNK_OVERLAP = 100
DOC_STORE_PATH = "rag_storage"

# Model for inference (OpenAI, Ollama, etc.)
LLM_PROVIDER = "lmstudio"
LLM_MODEL = "liquid/lfm2-1.2b"

